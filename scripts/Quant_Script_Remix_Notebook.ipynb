{"cells":[{"cell_type":"markdown","id":"b39a2acd","metadata":{"id":"b39a2acd"},"source":["\n","# Quant — Option C (Remix)\n","Minimal notebook that loads **World Data 2.0** and runs one method: **summary+correlation**, **regression**, **clustering**, or **pca**.\n"]},{"cell_type":"code","execution_count":null,"id":"2e4485fb","metadata":{"id":"2e4485fb"},"outputs":[],"source":["\n","# =========================\n","# CONFIG (EDIT HERE)\n","# =========================\n","DATA_URL = \"https://github.com/zachtilton/intermediate_analytics_ai/blob/main/World%20Data%202.0%20-%20Data.csv\"\n","\n","# Choose ONE method: \"summary+correlation\" | \"regression\" | \"clustering\" | \"pca\"\n","METHOD = \"summary+correlation\"\n","\n","# Columns (defaults chosen from header you provided)\n","COUNTRY_COL = \"Country\"\n","MEASURES = [\n","    \"GDP per Capita (2018)\",\n","    \"Life expectancy at birth (years)(2018)\",\n","    \"Life satisfaction in Cantril Ladder (2018)\",\n","]\n","\n","# Only used if METHOD == \"regression\"\n","REGRESSION_TARGET = \"Life satisfaction in Cantril Ladder (2018)\"\n","\n","# Only used if METHOD == \"clustering\"\n","K = 4  # sensible default k=3..6\n","\n","# Only used if METHOD == \"pca\"\n","N_COMPONENTS = 2  # 2 components for easy plotting\n","\n","# Optional: filter to subset of countries (must match values in COUNTRY_COL)\n","COUNTRY_FILTER = None  # e.g., [\"Sweden\", \"Japan\"]\n","\n","print(\"Config set. Edit METHOD/columns above as needed.\")\n"]},{"cell_type":"code","execution_count":null,"id":"985aeff1","metadata":{"id":"985aeff1"},"outputs":[],"source":["\n","import pandas as pd\n","import numpy as np\n","\n","def to_raw_github_url(url: str) -> str:\n","    # Convert GitHub page URL to raw content if needed\n","    if \"github.com\" in url and \"raw.githubusercontent.com\" not in url:\n","        url = url.replace(\"github.com/\", \"raw.githubusercontent.com/\")\n","        url = url.replace(\"/blob/\", \"/\")\n","    return url\n","\n","pd.set_option(\"display.width\", 120)\n","pd.set_option(\"display.max_columns\", 50)\n"]},{"cell_type":"code","execution_count":null,"id":"a8932bcb","metadata":{"id":"a8932bcb"},"outputs":[],"source":["\n","RAW_URL = to_raw_github_url(DATA_URL)\n","df = pd.read_csv(RAW_URL)\n","\n","print(\"Loaded shape:\", df.shape)\n","print(\"Columns:\")\n","print(list(df.columns))\n","\n","print(\"\\nPreview:\")\n","print(df.head(3).to_string(index=False))\n"]},{"cell_type":"code","execution_count":null,"id":"4a310440","metadata":{"id":"4a310440"},"outputs":[],"source":["\n","# Validate presence of columns\n","missing = [c for c in [COUNTRY_COL, *MEASURES] if c not in df.columns]\n","if missing:\n","    raise ValueError(f\"Missing columns: {missing}. Please edit COUNTRY_COL/MEASURES to match the CSV headers above.\")\n","\n","# Optional filter\n","if COUNTRY_FILTER:\n","    df = df[df[COUNTRY_COL].astype(str).isin(COUNTRY_FILTER)].copy()\n","\n","# Keep only needed cols for analysis (plus COUNTRY_COL)\n","use_cols = [COUNTRY_COL] + MEASURES\n","work = df[use_cols].dropna().copy()\n","\n","print(\"Working shape after dropna on selected measures:\", work.shape)\n"]},{"cell_type":"code","execution_count":null,"id":"5117e9d9","metadata":{"id":"5117e9d9"},"outputs":[],"source":["\n","# Run the selected method\n","result_scatter = None    # Will hold a DataFrame with columns: Country, x, y [, group]\n","pca_loadings = None      # Only if METHOD == \"pca\"\n","\n","method = METHOD.strip().lower()\n","\n","if method == \"summary+correlation\":\n","    # 1) Summary stats\n","    summary = work[MEASURES].describe().T\n","    print(\"\\n[SUMMARY]\")\n","    print(summary.to_string())\n","\n","    # 2) Correlation matrix\n","    corr = work[MEASURES].corr()\n","    print(\"\\n[CORRELATION]\")\n","    print(corr.round(3).to_string())\n","\n","    # 3) result_scatter (first two measures as x,y)\n","    x_col, y_col = MEASURES[0], (MEASURES[1] if len(MEASURES) > 1 else MEASURES[0])\n","    result_scatter = work[[COUNTRY_COL, x_col, y_col]].rename(columns={COUNTRY_COL:\"Country\", x_col:\"x\", y_col:\"y\"}).copy()\n","    print(\"\\n[result_scatter preview]\")\n","    print(result_scatter.head(10).to_string(index=False))\n","\n","elif method == \"regression\":\n","    # Features = MEASURES excluding target\n","    if REGRESSION_TARGET not in work.columns:\n","        raise ValueError(f\"REGRESSION_TARGET '{REGRESSION_TARGET}' not found in data.\")\n","\n","    features = [m for m in MEASURES if m != REGRESSION_TARGET]\n","    if len(features) == 0:\n","        raise ValueError(\"Need at least one feature (MEASURES excluding REGRESSION_TARGET).\")\n","\n","    try:\n","        from sklearn.linear_model import LinearRegression\n","    except Exception as e:\n","        raise RuntimeError(\"scikit-learn is required for regression. Try installing it first (e.g., pip install scikit-learn).\") from e\n","\n","    X = work[features].values\n","    y = work[REGRESSION_TARGET].values\n","    model = LinearRegression().fit(X, y)\n","    coefs = dict(zip(features, model.coef_.tolist()))\n","    intercept = float(model.intercept_)\n","    r2 = float(model.score(X, y))\n","\n","    print(\"\\n[REGRESSION RESULTS]\")\n","    print(\"Intercept:\", intercept)\n","    print(\"Coefficients:\")\n","    for k,v in coefs.items():\n","        print(f\"  {k}: {v:.4f}\")\n","    print(f\"R^2: {r2:.3f}\")\n","    print(\"\\n[INTERPRETATION] Higher absolute coefficients indicate stronger linear influence on the target given selected features.\")\n","\n","    # result_scatter uses first two features as x,y (if only one feature, y becomes target for simple scatter)\n","    if len(features) >= 2:\n","        x_col, y_col = features[0], features[1]\n","    else:\n","        x_col, y_col = features[0], REGRESSION_TARGET\n","    result_scatter = work[[COUNTRY_COL, x_col, y_col]].rename(columns={COUNTRY_COL:\"Country\", x_col:\"x\", y_col:\"y\"}).copy()\n","    print(\"\\n[result_scatter preview]\")\n","    print(result_scatter.head(10).to_string(index=False))\n","\n","elif method == \"clustering\":\n","    # Requires at least two measures\n","    if len(MEASURES) < 2:\n","        raise ValueError(\"Clustering needs at least two measures in MEASURES.\")\n","    try:\n","        from sklearn.cluster import KMeans\n","    except Exception as e:\n","        raise RuntimeError(\"scikit-learn is required for clustering. Try installing it first (e.g., pip install scikit-learn).\") from e\n","\n","    X = work[MEASURES].values\n","    km = KMeans(n_clusters=K, n_init=10, random_state=42).fit(X)\n","    labels = km.labels_\n","    print(\"\\n[CLUSTERING]\")\n","    unique, counts = np.unique(labels, return_counts=True)\n","    for u,c in zip(unique, counts):\n","        print(f\"cluster {u}: {c} rows\")\n","    print(\"Interpretation: clusters group countries with similar measure profiles.\")\n","\n","    # Scatter on first two measures, add cluster label\n","    x_col, y_col = MEASURES[0], MEASURES[1]\n","    result_scatter = (\n","        work[[COUNTRY_COL, x_col, y_col]].assign(group=labels)\n","        .rename(columns={COUNTRY_COL:\"Country\", x_col:\"x\", y_col:\"y\"})\n","        .copy()\n","    )\n","    print(\"\\n[result_scatter preview]\")\n","    print(result_scatter.head(10).to_string(index=False))\n","\n","elif method == \"pca\":\n","    if len(MEASURES) < 2:\n","        raise ValueError(\"PCA needs at least two measures in MEASURES.\")\n","    try:\n","        from sklearn.decomposition import PCA\n","    except Exception as e:\n","        raise RuntimeError(\"scikit-learn is required for PCA. Try installing it first (e.g., pip install scikit-learn).\") from e\n","\n","    X = work[MEASURES].values\n","    pca = PCA(n_components=N_COMPONENTS, random_state=42).fit(X)\n","    explained = pca.explained_variance_ratio_\n","    comps = pca.components_\n","    print(\"\\n[PCA] Explained variance ratio:\", [round(v,3) for v in explained])\n","\n","    # Loadings per component\n","    pca_loadings = []\n","    for i, comp in enumerate(comps):\n","        row = dict(zip(MEASURES, [float(v) for v in comp]))\n","        pca_loadings.append({\"component\": i+1, \"loadings\": row})\n","    print(\"\\n[Loadings]\")\n","    for row in pca_loadings:\n","        print(f\"Component {row['component']}:\")\n","        for k,v in row[\"loadings\"].items():\n","            print(f\"  {k}: {v:.3f}\")\n","\n","    # 2D result_scatter using first two PCs (pad with zeros if only 1 component requested)\n","    X_p = pca.transform(X)\n","    x = X_p[:,0]\n","    y = X_p[:,1] if X_p.shape[1] > 1 else np.zeros_like(x)\n","    result_scatter = pd.DataFrame({\n","        \"Country\": work[COUNTRY_COL].values,\n","        \"x\": x,\n","        \"y\": y\n","    })\n","    print(\"\\n[result_scatter preview]\")\n","    print(result_scatter.head(10).to_string(index=False))\n","\n","else:\n","    raise ValueError(f\"Unknown METHOD: {METHOD}\")\n"]},{"cell_type":"code","execution_count":null,"id":"7bca5192","metadata":{"id":"7bca5192"},"outputs":[],"source":["\n","# Simple key finding heuristic for scatter-ready results\n","try:\n","    r = np.corrcoef(result_scatter[\"x\"], result_scatter[\"y\"])[0,1]\n","    desc = \"positive\" if r >= 0 else \"negative\"\n","    strength = \"weak\" if abs(r) < 0.3 else \"moderate\" if abs(r) < 0.6 else \"strong\"\n","    print(f\"[KEY FINDING] Scatter x vs y shows a {strength} {desc} relationship (r ≈ {r:.2f}).\")\n","except Exception as e:\n","    print(\"Key finding calculation skipped:\", e)\n","\n","print(\"\\nDone. You can now explore `result_scatter` (and `pca_loadings` if PCA).\")\n"]}],"metadata":{"colab":{"provenance":[{"file_id":"1HWw3Oxe-iSrckiBw2a9kDXD6q0FYdq7_","timestamp":1758125676843}]},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":5}